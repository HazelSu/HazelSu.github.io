<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Wenxin Su (ËãèÊ±∂ËäØ)</title>
  
  
  <link href="http://example.com/atom.xml" rel="self"/>
  
  <link href="http://example.com/"/>
  <updated>2025-11-07T00:35:28.506Z</updated>
  <id>http://example.com/</id>
  
  <author>
    <name>Wenxin Su</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>ac_about</title>
    <link href="http://example.com/2025/11/06/ac-about/"/>
    <id>http://example.com/2025/11/06/ac-about/</id>
    <published>2025-11-06T21:56:32.000Z</published>
    <updated>2025-11-07T00:35:28.506Z</updated>
    
    <content type="html"><![CDATA[<h1 id="üß¨-About-Me"><a href="#üß¨-About-Me" class="headerlink" title="üß¨ About Me"></a>üß¨ About Me</h1><p>Hi, I am <strong>Wenxin Su</strong>, a Ph.D. candidate at the <a href="https://www.embl.org/sites/heidelberg/">European Molecular Biology Laboratory (EMBL), Heidelberg</a>, advised by <a href="https://www.embl.org/groups/kreshuk/">Dr. Anna Kreshuk</a>. </p><p>Before starting my Ph.D., I completed my master at University of Shanghai for Science and Technology in 2025. During this time, I conducted research in <strong>Source-free Domain Adaptation</strong> and <strong>Prompt Learning</strong> under the guidance of <a href="https://scholar.google.com/citations?user=8uhkD9QAAAAJ&hl=en">Dr. Song Tang</a>.</p><p>I am interested in developing <em>transfer learning, representation learning, and multimodal learning methods for biological image analysis</em>.</p><p><span style="background-color:#EAF2FB; color:#2B6CB0; font-weight:600;"> üí¨ I‚Äôm always open to collaboration and discussion ‚Äî if you‚Äôre interested in my research or have exciting ideas, feel free to reach out to me üòä! </span></p><hr><h1 id="üì∞-News"><a href="#üì∞-News" class="headerlink" title="üì∞ News "></a>üì∞ News <a id="News"></a></h1><ul><li><strong>Sep, 2025</strong> ‚Äî Joined the <strong>European Molecular Biology Laboratory (EMBL), Heidelberg</strong> for a Ph.D.! üéì</li><li><strong>Jun, 2025</strong> ‚Äî Graduated from <strong>University of Shanghai for Science and Technology! üéì</strong>  </li><li><strong>Feb, 2025</strong> ‚Äî Our paper, ‚ÄúDomain Adaptive Diabetic Retinopathy Grading with Model Absence and Flowing Data‚Äù, has been accepted by <strong>CVPR 2025</strong> !  </li><li><strong>Jan, 2025</strong> ‚Äî Our paper, ‚ÄúProxy Denoising for Source-Free Domain Adaptation‚Äù, has been accepted by <strong>ICLR 2025</strong>! <strong>Oral TOP1.8% üèÜ</strong></li><li><strong>Dec, 2024</strong> ‚Äî Our paper, ‚ÄúIs Foreground Prototype Sufficient? Few-Shot Medical Image Segmentation with Background-Fused Prototype‚Äù is out!  </li><li><strong>Mar, 2024</strong> ‚Äî Our paper, ‚ÄúUnified source-free domain adaptation‚Äù is out!  </li><li><strong>Feb, 2024</strong> ‚Äî Our paper, ‚ÄúSource-free domain adaptation with frozen multimodal foundation model‚Äù has been accepted by <strong>CVPR 2024</strong>! </li><li><strong>Jun, 2024</strong> ‚Äî Our paper, ‚ÄúModel adaptation via credible local context representation‚Äù, has been accepted by <strong>CAAI Transactions on Intelligence Technology</strong> !</li></ul><h1 id="üìö-Publications"><a href="#üìö-Publications" class="headerlink" title="üìö Publications "></a>üìö Publications <a id="Publications"></a></h1><hr><!-- ËÆ∫Êñá 1 --><div style="display:flex; align-items:flex-start; margin-bottom:1.5rem;">  <!-- Â∑¶‰æßÂÜÖÂÆπÔºöÂõæÁâá + ‰ºöËÆÆÊ†áÁ≠æ -->  <div style="position:relative; margin-right:20px; margin-top:10px;"> <!-- ‚ú® Êï¥‰Ωì‰∏ãÁßª‰∏ÄÁÇπ -->    <!-- ËìùÂ∫ïÊ†áÁ≠æ -->    <div style="      width:90px;      background-color:#2f5bb7;      color:white;      font-weight:bold;      text-align:center;      border-radius:6px;      padding:2px 16px;      font-size:14px;      position:absolute;      top:-14px; /* ‚ú® ÂéüÊú¨ -26px Êîπ‰∏∫ -14pxÔºåÂàöÂ•Ω‰∏çÈáçÂè† */      left:0;      box-shadow:0 1px 3px rgba(0,0,0,0.2);    ">      CVPR    </div>    <!-- ÂõæÁâá -->    <img src="/img/paper_1.png" alt="CVPR Paper"      style="width:120px; height:auto; border-radius:6px; margin-top:16px;">  </div>  <!-- Âè≥‰æßËÆ∫Êñá‰ø°ÊÅØ -->  <div style="line-height:1.35;">    <h4 style="margin:0 0 6px 0; font-size:18px; font-weight:700; line-height:1.3;">      <!-- Domain Adaptive Diabetic Retinopathy Grading with Model Absence and Flowing Data -->      <a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Tang_Source-Free_Domain_Adaptation_with_Frozen_Multimodal_Foundation_Model_CVPR_2024_paper.pdf" target="_blank" style="text-decoration:none; color:#2c3e50;">        Domain Adaptive Diabetic Retinopathy Grading with Model Absence and Flowing Data      </a>    </h4>    <p style="margin:4px 0; line-height:1.35;">      <b>Wenxin Su</b>, Song Tang, Xiaofeng Liu, Xiaojing Yi, Mao Ye, Chunxiao Zu, Jiahao Li, and Xiatian Zhu<br>      <i>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2025</i>    </p>    <!-- <div style="margin-top:6px;">      <a href="#" class="btn" style="padding:4px 10px; margin-right:6px; background:#666; color:#fff; border-radius:5px; text-decoration:none;">DOI</a>      <a href="#" class="btn" style="padding:4px 10px; margin-right:6px; background:#666; color:#fff; border-radius:5px; text-decoration:none;">BIB</a>      <a href="#" class="btn" style="padding:4px 10px; background:#666; color:#fff; border-radius:5px; text-decoration:none;">CODE</a>    </div> -->  </div></div><hr><!-- ËÆ∫Êñá 2 --><div style="display:flex; align-items:flex-start; margin-bottom:1.5rem;">  <!-- Â∑¶‰æßÂÜÖÂÆπÔºöÂõæÁâá + ‰ºöËÆÆÊ†áÁ≠æ -->  <div style="position:relative; margin-right:20px; margin-top:10px;"> <!-- ‚ú® Êï¥‰Ωì‰∏ãÁßª‰∏ÄÁÇπ -->    <!-- ËìùÂ∫ïÊ†áÁ≠æ -->    <div style="      width:90px;      background-color:#2f5bb7;      color:white;      font-weight:bold;      text-align:center;      border-radius:6px;      padding:2px 16px;      font-size:14px;      position:absolute;      top:-14px; /* ‚ú® ÂéüÊú¨ -26px Êîπ‰∏∫ -14pxÔºåÂàöÂ•Ω‰∏çÈáçÂè† */      left:0;      box-shadow:0 1px 3px rgba(0,0,0,0.2);    ">      ICLR Oral    </div>    <!-- ÂõæÁâá -->    <img src="/img/paper_2.png" alt="CVPR Paper"      style="width:120px; height:auto; border-radius:6px; margin-top:16px;">  </div>  <!-- Âè≥‰æßËÆ∫Êñá‰ø°ÊÅØ -->  <div style="line-height:1.35;">    <h4 style="margin:0 0 6px 0; font-size:18px; font-weight:700; line-height:1.3;">      <!-- Domain Adaptive Diabetic Retinopathy Grading with Model Absence and Flowing Data -->      <a href="https://arxiv.org/pdf/2406.01658?" target="_blank" style="text-decoration:none; color:#2c3e50;">        Proxy Denoising for Source-Free Domain Adaptation      </a>    </h4>    <p style="margin:4px 0; line-height:1.35;">      Song Tang, <b>Wenxin Su</b>, Mao Ye, and Xiatian Zhu<br>      <i>International Conference on Learning Representations (ICLR) 2025 (Oral, TOP1.8%), 2025</i>    </p>    <!-- <div style="margin-top:6px;">      <a href="#" class="btn" style="padding:4px 10px; margin-right:6px; background:#666; color:#fff; border-radius:5px; text-decoration:none;">DOI</a>      <a href="#" class="btn" style="padding:4px 10px; margin-right:6px; background:#666; color:#fff; border-radius:5px; text-decoration:none;">BIB</a>      <a href="#" class="btn" style="padding:4px 10px; background:#666; color:#fff; border-radius:5px; text-decoration:none;">CODE</a>    </div> -->  </div></div><hr><!-- ËÆ∫Êñá 3 --><div style="display:flex; align-items:flex-start; margin-bottom:1.5rem;">  <!-- Â∑¶‰æßÂÜÖÂÆπÔºöÂõæÁâá + ‰ºöËÆÆÊ†áÁ≠æ -->  <div style="position:relative; margin-right:20px; margin-top:10px;"> <!-- ‚ú® Êï¥‰Ωì‰∏ãÁßª‰∏ÄÁÇπ -->    <!-- ËìùÂ∫ïÊ†áÁ≠æ -->    <div style="      width:90px;      background-color:#2f5bb7;      color:white;      font-weight:bold;      text-align:center;      border-radius:6px;      padding:2px 16px;      font-size:14px;      position:absolute;      top:-14px; /* ‚ú® ÂéüÊú¨ -26px Êîπ‰∏∫ -14pxÔºåÂàöÂ•Ω‰∏çÈáçÂè† */      left:0;      box-shadow:0 1px 3px rgba(0,0,0,0.2);    ">      CVPR    </div>    <!-- ÂõæÁâá -->    <img src="/img/paper_3.png" alt="CVPR Paper"      style="width:120px; height:auto; border-radius:6px; margin-top:16px;">  </div>  <!-- Âè≥‰æßËÆ∫Êñá‰ø°ÊÅØ -->  <div style="line-height:1.35;">    <h4 style="margin:0 0 6px 0; font-size:18px; font-weight:700; line-height:1.3;">      <!-- Domain Adaptive Diabetic Retinopathy Grading with Model Absence and Flowing Data -->      <a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Tang_Source-Free_Domain_Adaptation_with_Frozen_Multimodal_Foundation_Model_CVPR_2024_paper.pdf" target="_blank" style="text-decoration:none; color:#2c3e50;">        Source-Free Domain Adaptation with Frozen Multimodal Foundation Model      </a>    </h4>    <p style="margin:4px 0; line-height:1.35;">      Song Tang, <b>Wenxin Su</b>, Mao Ye, and Xiatian Zhu<br>      <i>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2024</i>    </p>    <!-- <div style="margin-top:6px;">      <a href="#" class="btn" style="padding:4px 10px; margin-right:6px; background:#666; color:#fff; border-radius:5px; text-decoration:none;">DOI</a>      <a href="#" class="btn" style="padding:4px 10px; margin-right:6px; background:#666; color:#fff; border-radius:5px; text-decoration:none;">BIB</a>      <a href="#" class="btn" style="padding:4px 10px; background:#666; color:#fff; border-radius:5px; text-decoration:none;">CODE</a>    </div> -->  </div></div><hr><!-- ËÆ∫Êñá 4 --><div style="display:flex; align-items:flex-start; margin-bottom:1.5rem;">  <!-- Â∑¶‰æßÂÜÖÂÆπÔºöÂõæÁâá + ‰ºöËÆÆÊ†áÁ≠æ -->  <div style="position:relative; margin-right:20px; margin-top:10px;"> <!-- ‚ú® Êï¥‰Ωì‰∏ãÁßª‰∏ÄÁÇπ -->    <!-- ËìùÂ∫ïÊ†áÁ≠æ -->    <div style="      width:90px;      background-color:#2f5bb7;      color:white;      font-weight:bold;      text-align:center;      border-radius:6px;      padding:2px 16px;      font-size:14px;      position:absolute;      top:-14px; /* ‚ú® ÂéüÊú¨ -26px Êîπ‰∏∫ -14pxÔºåÂàöÂ•Ω‰∏çÈáçÂè† */      left:0;      box-shadow:0 1px 3px rgba(0,0,0,0.2);    ">      Arxiv    </div>    <!-- ÂõæÁâá -->    <img src="/img/paper_4.png" alt="CVPR Paper"      style="width:120px; height:auto; border-radius:6px; margin-top:16px;">  </div>  <!-- Âè≥‰æßËÆ∫Êñá‰ø°ÊÅØ -->  <div style="line-height:1.35;">    <h4 style="margin:0 0 6px 0; font-size:18px; font-weight:700; line-height:1.3;">      <!-- Domain Adaptive Diabetic Retinopathy Grading with Model Absence and Flowing Data -->      <a href="https://arxiv.org/pdf/2403.07601" target="_blank" style="text-decoration:none; color:#2c3e50;">        Unified Source-free Domain Adaptation      </a>    </h4>    <p style="margin:4px 0; line-height:1.35;">      Song Tang, <b>Wenxin Su</b>, Mao Ye, Jianwei Zhang, and Xiatian Zhu<br>      <!-- <i>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2024</i> -->    </p>    <!-- <div style="margin-top:6px;">      <a href="#" class="btn" style="padding:4px 10px; margin-right:6px; background:#666; color:#fff; border-radius:5px; text-decoration:none;">DOI</a>      <a href="#" class="btn" style="padding:4px 10px; margin-right:6px; background:#666; color:#fff; border-radius:5px; text-decoration:none;">BIB</a>      <a href="#" class="btn" style="padding:4px 10px; background:#666; color:#fff; border-radius:5px; text-decoration:none;">CODE</a>    </div> -->  </div></div><hr>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;üß¨-About-Me&quot;&gt;&lt;a href=&quot;#üß¨-About-Me&quot; class=&quot;headerlink&quot; title=&quot;üß¨ About Me&quot;&gt;&lt;/a&gt;üß¨ About Me&lt;/h1&gt;&lt;p&gt;Hi, I am &lt;strong&gt;Wenxin Su&lt;/strong</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://example.com/2024/05/23/Resume/"/>
    <id>http://example.com/2024/05/23/Resume/</id>
    <published>2024-05-23T10:16:54.119Z</published>
    <updated>2025-11-02T15:16:48.775Z</updated>
    
    <content type="html"><![CDATA[<hr><h1 id="title-Hi-I‚Äôm-Wenxin-Su-a-Ph-D-student-at-the-European-Molecular-Biology-Laboratory-EMBL-supervised-by-Dr-Anna-Kreshuk-https-www-embl-org-groups-kreshuk-My-research-focused-on-transfer-learning-and-representation-learning-for-biological-image-analysis-Before-starting-my-Ph-D-I-completed-dual-master‚Äôs-degrees-at-the-University-of-Shanghai-for-Science-and-Technology-under-the-supervision-of-Assoc-Prof-Song-Tang-https-scholar-google-com-citations-user-8uhkD9QAAAAJ-hl-en-oi-ao"><a href="#title-Hi-I‚Äôm-Wenxin-Su-a-Ph-D-student-at-the-European-Molecular-Biology-Laboratory-EMBL-supervised-by-Dr-Anna-Kreshuk-https-www-embl-org-groups-kreshuk-My-research-focused-on-transfer-learning-and-representation-learning-for-biological-image-analysis-Before-starting-my-Ph-D-I-completed-dual-master‚Äôs-degrees-at-the-University-of-Shanghai-for-Science-and-Technology-under-the-supervision-of-Assoc-Prof-Song-Tang-https-scholar-google-com-citations-user-8uhkD9QAAAAJ-hl-en-oi-ao" class="headerlink" title="title: Hi! I‚Äôm Wenxin Su, a Ph.D. student at the European Molecular Biology Laboratory (EMBL), supervised by Dr. Anna Kreshuk (https://www.embl.org/groups/kreshuk/). My research focused on transfer learning and representation learning for biological image analysis. Before starting my Ph.D., I completed dual master‚Äôs degrees at the University of Shanghai for Science and Technology, under the supervision of Assoc. Prof. Song Tang (https://scholar.google.com/citations?user=8uhkD9QAAAAJ&amp;hl=en&amp;oi=ao)."></a>title: Hi! I‚Äôm Wenxin Su, a Ph.D. student at the European Molecular Biology Laboratory (EMBL), supervised by Dr. Anna Kreshuk (<a href="https://www.embl.org/groups/kreshuk/">https://www.embl.org/groups/kreshuk/</a>). My research focused on transfer learning and representation learning for biological image analysis. Before starting my Ph.D., I completed dual master‚Äôs degrees at the University of Shanghai for Science and Technology, under the supervision of Assoc. Prof. Song Tang (<a href="https://scholar.google.com/citations?user=8uhkD9QAAAAJ&hl=en&oi=ao">https://scholar.google.com/citations?user=8uhkD9QAAAAJ&amp;hl=en&amp;oi=ao</a>).</h1><hr><p>I am currently pursuing a M.S. in the Institute of Machine Intelligence at University of Shanghai for Science and Technology (USST), supervised by <a href="https://scholar.google.com/citations?user=8uhkD9QAAAAJ&hl=en&oi=ao">Assoc. Prof. Song Tang</a>.</p><!-- ## Picture![](./image.jpg) --><!-- <img src="./image.jpg" align="center"> --><h2 id="Information"><a href="#Information" class="headerlink" title="Information"></a>Information</h2><p>Email: <a href="mailto:&#115;&#117;&#119;&#x65;&#x6e;&#x78;&#x69;&#110;&#x34;&#51;&#64;&#x67;&#x6d;&#x61;&#105;&#x6c;&#x2e;&#x63;&#111;&#109;">&#115;&#117;&#119;&#x65;&#x6e;&#x78;&#x69;&#110;&#x34;&#51;&#64;&#x67;&#x6d;&#x61;&#105;&#x6c;&#x2e;&#x63;&#111;&#109;</a><br>Research Interests: Computer Vision; Transfer Learning; Medical Image Analysis<br>Google Scholar: <a href="https://scholar.google.com/citations?user=BPQ9bSwAAAAJ">https://scholar.google.com/citations?user=BPQ9bSwAAAAJ</a></p><h2 id="Publications"><a href="#Publications" class="headerlink" title="Publications"></a>Publications</h2><ul><li>[<strong>CVPR‚Äô25</strong>] <a href="https://arxiv.org/pdf/2412.01203"><strong>Wenxin Su</strong>, Song Tang, Xiaofeng Liu, Xiaojing Yi, Mao Ye, Chunxiao Zu, Jiahao Li, Xiatian Zhu. Domain Adaptive Diabetic Retinopathy Grading with Model Absence and Flowing Data.</a></li><li>[<strong>ICLR‚Äô25 (oral, acceptance rate ‚âà 1.8%)</strong>] <a href="https://arxiv.org/abs/2406.01658">Song Tang and <strong>Wenxin Su</strong>, Mao Ye, Jianwei Zhang and Xiatian Zhu. Proxy Denoising for Source-Free Domain Adaptation.</a></li><li>[<strong>ARXIV‚Äô24</strong>] <a href="https://arxiv.org/abs/2403.07601">Song Tang, <strong>Wenxin Su</strong>, Mao Ye, Jianwei Zhang and Xiatian Zhu. Unified source-free domain adaptation.</a> and <a href="https://github.com/tntek/source-free-domain-adaptation/blob/main/src/methods/oh/lcfd.py"><em>Code</em></a></li><li>[<strong>CVPR‚Äô24</strong>] <a href="https://arxiv.org/abs/2311.16510v3">Song Tang, <strong>Wenxin Su</strong>, Mao Ye, and Xiatian Zhu. Source-free domain adaptation with frozen multimodal foundation model.</a> and <a href="https://www.taulab.cc/proj/sfda/cvpr24/difo/index.html"><em>project page</em></a></li><li>[<strong>CAAI TRIT‚Äô23</strong>] <a href="https://ietresearch.onlinelibrary.wiley.com/doi/pdf/10.1049/cit2.12228">Song Tang, <strong>Wenxin Su</strong>, Yan Yang, Lijuan Chen, and Mao Ye. Model adaptation via credible local context representation.</a> and <a href="https://github.com/tntek/CLCR"><em>Code</em></a></li></ul><h2 id="Research-Project"><a href="#Research-Project" class="headerlink" title="Research Project"></a>Research Project</h2><ul><li>Unified Source-Free Domain Adaptation (SFDA) framework (<strong>160 stars</strong>), 2024.03 - Present<ul><li>Independently designed and implemented the first unified Source-Free Domain Adaptation (SFDA) framework project based on PyTorch. The project includes the 10 most mainstream SFDA methods from 2020 to 2024, such as SHOT, NRC, COWA, AdaContrast, PLUE, and our team‚Äôs LCFD, DIFO, TPDS, SCLM, and GKD.</li><li><strong><a href="https://github.com/tntek/source-free-domain-adaptation">https://github.com/tntek/source-free-domain-adaptation</a></strong></li></ul></li></ul><h2 id="Education-and-Professional"><a href="#Education-and-Professional" class="headerlink" title="Education and Professional"></a>Education and Professional</h2><ul><li><p>USST, China, 2022.09 - Present</p><ul><li>Master Student, Biomedical Engineering </li><li>Advisor: Assoc. Prof. Song Tang</li><li>GPA: 3.9&#x2F;4.0 Top 5%</li></ul></li><li><p>Chengdu Aosailixing Information Technology Service Co., Ltd., China, 2021.03 ‚Äì 2022.04</p><ul><li>Data Analyst</li><li>Responsibilities: Build machine learning models to analyze data</li></ul></li><li><p>Halmstad University, Sweden, 2018.09 ‚Äì 2019.02</p><ul><li>Exchange Student, Computer Science</li></ul></li><li><p>Chengdu Jincheng College, China, 2017.09 ‚Äì 2021.06</p><ul><li>B.S.,(Honor) Internet of Things Engineering </li><li>GPA: 3.6&#x2F;4</li></ul></li></ul><h2 id="Research-Experience"><a href="#Research-Experience" class="headerlink" title="Research Experience"></a>Research Experience</h2><ul><li>Source-free Domain Adaptation, 2022.04 ‚Äì Present</li><li>Diabetic Retinopathy Grading 2024.07 ‚Äì Present</li></ul><h2 id="Academic-Service"><a href="#Academic-Service" class="headerlink" title="Academic Service"></a>Academic Service</h2><ul><li>Served as a reviewer for AAAI 2024 and ICLR 2025</li><li>Presented a talk at the CVPR 2024 poster session.</li></ul><h2 id="Selected-Honor-Awards"><a href="#Selected-Honor-Awards" class="headerlink" title="Selected Honor &amp; Awards"></a>Selected Honor &amp; Awards</h2><p>Frist Prize Scholarship of USST </p><ul><li>Top 5% Mar, 2024</li></ul><p>National Scholarship for Postgraduates</p><ul><li>Top 1% Sep, 2023</li></ul><p>Excellent Student of Chengdu Jincheng College</p><ul><li>Top 1% May, 2021</li></ul><p>Second Prize Scholarship at Chengdu Jincheng College</p><ul><li>Top 20% Sep, 2019</li></ul><h2 id="Skills-and-Hobbies"><a href="#Skills-and-Hobbies" class="headerlink" title="Skills and Hobbies"></a>Skills and Hobbies</h2><ul><li>Programming and others: Python, PyTorch, C, R, Data Visualization, Latex, Kettle, MySQL</li><li>Hobbies: Hiking, Runing, Cycling, Basketball</li></ul><h2 id="Picture"><a href="#Picture" class="headerlink" title="Picture"></a>Picture</h2><table rules="none" align="center">    <tr>        <td>            <center>                <img src="cvpr2024.jpg" width="80%" />                <br/>                <font color="AAAAAA">CVPR2024</font>            </center>        </td>        <td>            <center>                <img src="hiking.jpg" width="80%" />                <br/>                <font color="AAAAAA">Hiking</font>            </center>        </td>    </tr></table>]]></content>
    
    
      
      
    <summary type="html">&lt;hr&gt;
&lt;h1 id=&quot;title-Hi-I‚Äôm-Wenxin-Su-a-Ph-D-student-at-the-European-Molecular-Biology-Laboratory-EMBL-supervised-by-Dr-Anna-Kreshuk-https-www</summary>
      
    
    
    
    
  </entry>
  
</feed>
